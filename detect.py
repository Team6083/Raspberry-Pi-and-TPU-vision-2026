import cv2
import numpy as np
import time
import threading
import subprocess
import os
import csv  # ğŸ”¥ã€æ–°å¢ã€‘CSV æ¨¡çµ„
from datetime import datetime
import ntcore
from flask import Flask, Response, render_template_string, jsonify
from pycoral.utils.edgetpu import make_interpreter
from pycoral.adapters import common

# ==================== åƒæ•¸è¨­å®š ====================
MODEL_PATH = "best_full_integer_quant_edgetpu_4.tflite"
TEAM_NUMBER = 6083
EXPOSURE_VAL = 30
BRIGHTNESS_VAL = 90
ALPHA = 0.2
CALIB_X_OFFSET = 10 
CALIB_Y_OFFSET = -10
CALIB_SCALE = 1.1

VIDEO_DIR = "captured_videos"
os.makedirs(VIDEO_DIR, exist_ok=True)
# =================================================

app = Flask(__name__)
output_frame = None
lock = threading.Lock()

s_x, s_w = 0, 0
current_ball_count = 0
current_target_x, current_target_y = 0.0, 0.0
detection_counter = 0
ENABLE_NT = False
current_brightness = BRIGHTNESS_VAL
brightness_changed = False
last_target_center = None

# ğŸ”¥ã€ä¿®æ”¹ã€‘éŒ„å½±ç›¸é—œè®Šæ•¸
is_recording = False
video_writer = None
csv_file = None   # ğŸ”¥ CSV æª”æ¡ˆç‰©ä»¶
csv_writer = None # ğŸ”¥ CSV å¯«å…¥å™¨
frame_idx = 0     # ğŸ”¥ å¹€æ•¸è¨ˆæ•¸å™¨

class TFLiteTranslator:
    def __init__(self, model_path):
        self.interpreter = make_interpreter(model_path)
        self.interpreter.allocate_tensors()
        self.output_details = self.interpreter.get_output_details()[0]
        self.o_scale, self.o_zp = self.output_details['quantization']

    def process(self, letterbox_img):
        img = cv2.cvtColor(letterbox_img, cv2.COLOR_BGR2RGB)
        common.set_input(self.interpreter, img)
        self.interpreter.invoke()
        raw_output = self.interpreter.get_tensor(self.output_details['index'])[0]
        data = (raw_output.astype(np.float32) - self.o_zp) * self.o_scale
        return data.T if data.shape[0] == 5 else data

def vision_worker():
    global output_frame, s_x, s_w, detection_counter, current_ball_count
    global current_target_x, current_target_y, current_brightness, brightness_changed, last_target_center
    global is_recording, video_writer, csv_file, csv_writer, frame_idx # ğŸ”¥ å¼•ç”¨è®Šæ•¸
    
    translator = TFLiteTranslator(MODEL_PATH)
    cap = cv2.VideoCapture(0, cv2.CAP_V4L2)
    if not cap.isOpened(): cap = cv2.VideoCapture(1, cv2.CAP_V4L2)

    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 1)
    cap.set(cv2.CAP_PROP_EXPOSURE, EXPOSURE_VAL)
    cap.set(cv2.CAP_PROP_BRIGHTNESS, current_brightness)
    cap.set(cv2.CAP_PROP_GAIN, 0)

    # NT åˆå§‹åŒ– (çœç•¥...)
    if ENABLE_NT:
        inst = ntcore.NetworkTableInstance.getDefault()
        table = inst.getTable("6083_Vision")
        x_pub = table.getDoubleTopic("closest_x").publish()
        y_pub = table.getDoubleTopic("closest_dist").publish()
        count_pub = table.getIntegerTopic("ball_count").publish()
        inst.setServerTeam(TEAM_NUMBER)
        inst.startClient4("RPi_6083_Calibrated")

    def terminal_display():
        while True:
            time.sleep(1.0)
    threading.Thread(target=terminal_display, daemon=True).start()

    while True:
        if brightness_changed:
            cap.set(cv2.CAP_PROP_BRIGHTNESS, current_brightness)
            brightness_changed = False
        
        ret, frame = cap.read()
        if not ret: continue

        # ==========================================
        # ğŸ”¥ğŸ”¥ğŸ”¥ éŒ„å½±èˆ‡ CSV åˆå§‹åŒ– ğŸ”¥ğŸ”¥ğŸ”¥
        # ==========================================
        if is_recording:
            if video_writer is None:
                # æª”åæ™‚é–“æˆ³è¨˜
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # 1. å»ºç«‹å½±ç‰‡
                vid_filename = os.path.join(VIDEO_DIR, f"{timestamp}.avi")
                fourcc = cv2.VideoWriter_fourcc(*'MJPG') 
                video_writer = cv2.VideoWriter(vid_filename, fourcc, 30.0, (640, 480))
                
                # 2. å»ºç«‹ CSV (åŒæª”åï¼Œä¸åŒå‰¯æª”å)
                csv_filename = os.path.join(VIDEO_DIR, f"{timestamp}.csv")
                csv_file = open(csv_filename, 'w', newline='')
                csv_writer = csv.writer(csv_file)
                # å¯«å…¥æ¨™é¡Œåˆ—ï¼šå¹€æ•¸, Xåº§æ¨™, Yåº§æ¨™, å¯¬, é«˜, ä¿¡å¿ƒåº¦
                csv_writer.writerow(["Frame", "X", "Y", "W", "H", "Confidence"])
                
                frame_idx = 0 # é‡ç½®è¨ˆæ•¸
                print(f"ğŸ”´ é–‹å§‹éŒ„å½±: {vid_filename}")
            
            # å¯«å…¥ä¹¾æ·¨å½±åƒ
            video_writer.write(frame)
            frame_idx += 1
        else:
            # åœæ­¢éŒ„å½±èˆ‡é—œé–‰æª”æ¡ˆ
            if video_writer is not None:
                video_writer.release()
                video_writer = None
                csv_file.close() # é—œé–‰ CSV
                csv_file = None
                print("â¹ åœæ­¢éŒ„å½±ï¼Œæª”æ¡ˆå·²å„²å­˜ã€‚")
        
        # ==========================================
        #  å½±åƒè¾¨è­˜æµç¨‹
        # ==========================================
        resized_240 = cv2.resize(frame, (320, 240))
        input_canvas = np.zeros((320, 320, 3), dtype=np.uint8)
        input_canvas[40:280, 0:320] = resized_240

        data = translator.process(input_canvas)
        boxes, confs = [], []
        
        mask = data[:, 4] > 0.35 
        for row in data[mask]:
            xc, yc, w, h, conf = row
            # é‚„åŸèˆ‡æ ¡æ­£...
            real_x = xc * 640 + CALIB_X_OFFSET
            real_y = ((yc * 320 - 40) / 240) * 480 + CALIB_Y_OFFSET
            real_w = w * 640 * CALIB_SCALE
            real_h = (h * 320 / 240) * 480 * CALIB_SCALE
            
            # è¨ˆç®—å·¦ä¸Šè§’åº§æ¨™
            x1, y1 = int(real_x - real_w/2), int(real_y - real_h/2)
            w_int, h_int = int(real_w), int(real_h)

            boxes.append([x1, y1, w_int, h_int])
            confs.append(float(conf))

        indices = cv2.dnn.NMSBoxes(boxes, confs, 0.35, 0.45)
        
        # ==========================================
        # ğŸ”¥ğŸ”¥ğŸ”¥ å°‡è¾¨è­˜çµæœå¯«å…¥ CSV ğŸ”¥ğŸ”¥ğŸ”¥
        # ==========================================
        if is_recording and csv_writer is not None:
            if len(indices) > 0:
                for i in indices.flatten():
                    b = boxes[i]
                    c = confs[i]
                    # æ ¼å¼: Frame, X, Y, W, H, Conf
                    csv_writer.writerow([frame_idx, b[0], b[1], b[2], b[3], f"{c:.2f}"])
            else:
                # é€™ä¸€å¹€æ²’æŠ“åˆ°æ±è¥¿ï¼Œå¯«å…¥ç©ºç´€éŒ„ (æ–¹ä¾¿é™¤éŒ¯)
                csv_writer.writerow([frame_idx, -1, -1, -1, -1, 0])

        # ==========================================
        #  å¾ŒçºŒé‚è¼¯ (é¸ç›®æ¨™ã€ç•«åœ–) ä¿æŒä¸è®Š
        # ==========================================
        if len(indices) > 0:
            detection_counter += 1
            if detection_counter >= 2:
                current_ball_count = len(indices)
                all_valid_boxes = [boxes[i] for i in indices.flatten()]
                all_confs = [confs[i] for i in indices.flatten()]
                
                # ... (åŸæœ‰çš„é¸ç›®æ¨™é‚è¼¯) ...
                best_score = -999
                target_box = None
                for i, b in enumerate(all_valid_boxes):
                     # ... (è¨ˆç®—åˆ†æ•¸) ...
                     y_score = (b[1] + b[3]) / 480.0
                     conf_score = all_confs[i]
                     total_score = (y_score * 0.7) + (conf_score * 0.3)
                     if total_score > best_score:
                        best_score = total_score
                        target_box = b

                if target_box:
                    last_target_center = (target_box[0] + target_box[2]/2, target_box[1] + target_box[3]/2)
                    s_x = int(ALPHA * target_box[0] + (1 - ALPHA) * s_x)
                    s_w = int(ALPHA * target_box[2] + (1 - ALPHA) * s_w)
                    current_target_x = ((s_x + s_w/2) / 640.0) * 2 - 1
                    current_target_y = (target_box[1] + target_box[3]) / 480.0
                    
                    if ENABLE_NT:
                        x_pub.set(current_target_x)
                        y_pub.set(current_target_y)
                        count_pub.set(current_ball_count)

                    for b in all_valid_boxes:
                        is_target = (b == target_box)
                        color = (0, 255, 0) if is_target else (100, 100, 100)
                        cv2.rectangle(frame, (b[0], b[1]), (b[0]+b[2], b[1]+b[3]), color, 3 if is_target else 1)
                    
                    # ç•«ä¸­å¿ƒé»
                    target_cx = int(s_x + s_w/2)
                    target_cy = int(target_box[1] + target_box[3]/2)
                    cv2.circle(frame, (target_cx, target_cy), 5, (0, 0, 255), -1)
                    cv2.line(frame, (320, 240), (target_cx, target_cy), (0, 255, 255), 2)
                    cv2.putText(frame, f"OFFSET {current_target_x:.2f}", (s_x, target_box[1]-10), 0, 0.7, (0, 255, 0), 2)

        else:
            detection_counter = 0
            current_ball_count = 0
            if ENABLE_NT: count_pub.set(0)

        if is_recording:
             cv2.circle(frame, (620, 20), 10, (0, 0, 255), -1)

        with lock:
            output_frame = frame.copy()

# --- Flask éƒ¨åˆ†ä¸éœ€è¦å‹• ---
HTML_TEMPLATE = '''
<html>
<head><style>
    body { background: #1a1a1a; color: white; text-align: center; font-family: monospace; }
    .stat-box { background: #333; padding: 15px; margin: 10px; border-radius: 12px; display: inline-block; min-width: 150px; border: 1px solid #555; vertical-align: top; }
    .val { font-size: 32px; color: #ffff00; font-weight: bold; margin: 5px 0; }
    .label { color: #aaa; font-size: 14px; text-transform: uppercase; }
    .btn { background: #444; color: white; border: 1px solid #777; padding: 5px 15px; font-size: 18px; border-radius: 5px; cursor: pointer; margin: 0 5px; }
    .btn:hover { background: #666; } .btn:active { background: #00ff00; color: black; }
    
    /* éŒ„å½±æŒ‰éˆ•æ¨£å¼ */
    .btn-rec { background: #27ae60; width: 200px; padding: 10px; font-weight: bold; margin-top: 10px; border-radius: 8px;}
    .recording { background: #c0392b; animation: pulse 1s infinite; }
    @keyframes pulse { 0% { opacity: 1; } 50% { opacity: 0.7; } 100% { opacity: 1; } }
    
    .connected { color: #00ff00; } .local { color: #ff4444; }
</style>
<script>
    function adjustBrightness(val) {
        fetch('/adjust_brightness/' + val).then(r => r.json()).then(data => {
            document.getElementById('bright_val').innerText = data.new_brightness;
        });
    }

    // éŒ„å½±æ§åˆ¶
    function toggleRecord() {
        fetch('/toggle_record').then(r => r.json()).then(data => {
            updateRecButton(data.is_recording);
        });
    }

    function updateRecButton(isRec) {
        let btn = document.getElementById('recBtn');
        if (isRec) {
            btn.innerText = "â¹ åœæ­¢éŒ„å½± (REC)";
            btn.classList.add("recording");
        } else {
            btn.innerText = "ğŸ”´ é–‹å§‹è’é›†è³‡æ–™ (Start)";
            btn.classList.remove("recording");
        }
    }

    setInterval(function(){
        fetch('/get_status').then(r => r.json()).then(data => {
            document.getElementById('count').innerText = data.count;
            document.getElementById('tx').innerText = data.tx.toFixed(2);
            document.getElementById('ty').innerText = data.ty.toFixed(2);
            // åŒæ­¥éŒ„å½±ç‹€æ…‹
            updateRecButton(data.is_recording);
        });
    }, 500);
</script>
</head>
<body>
    <h1 style="color: #00ff00; text-shadow: 0 0 10px #00ff00;">6083 INTAKE DASHBOARD</h1>
    
    <div class="stat-box">
        <div class="label">ç•¶å‰äº®åº¦</div>
        <div id="bright_val" class="val">{{ br }}</div>
        <button class="btn" onclick="adjustBrightness(-10)">- 10</button>
        <button class="btn" onclick="adjustBrightness(10)">+ 10</button>
    </div>

    <div class="stat-box">
        <div class="label">å ´ä¸Šçƒæ•¸</div>
        <div id="count" class="val">0</div>
    </div>

    <div class="stat-box">
        <div class="label">ç›®æ¨™ X åç§»</div>
        <div id="tx" class="val">0.00</div>
    </div>
    
    <div class="stat-box">
        <div class="label">ç›®æ¨™è·é›¢ (Y)</div>
        <div id="ty" class="val" style="color: #00ff00;">0.00</div>
    </div>

    <br>
    <button id="recBtn" class="btn btn-rec" onclick="toggleRecord()">ğŸ”´ é–‹å§‹è’é›†è³‡æ–™ (Start)</button>

    <div style="margin-top: 10px;">
        <span class="{{ 'connected' if nt else 'local' }}" style="font-weight:bold; font-size: 18px;">
            {{ 'â— NETWORKTABLES CONNECTED' if nt else 'â— LOCAL MODE' }}
        </span>
    </div>
    <img src="/video_feed" width="640" style="border: 3px solid #555; border-radius: 10px; margin-top: 15px; box-shadow: 0 0 20px rgba(0,255,0,0.1);">
</body>
</html>
'''

@app.route('/')
def index(): 
    return render_template_string(HTML_TEMPLATE, nt=ENABLE_NT, br=current_brightness)

# ğŸ”¥ã€æ–°å¢ã€‘éŒ„å½±æ§åˆ¶ API
@app.route('/toggle_record')
def toggle_record():
    global is_recording
    is_recording = not is_recording
    return jsonify({"is_recording": is_recording})

@app.route('/adjust_brightness/<int:val>')
def adjust_brightness(val):
    global current_brightness, brightness_changed
    current_brightness = max(0, min(255, current_brightness + val))
    brightness_changed = True
    return jsonify({"new_brightness": current_brightness})

@app.route('/get_status')
def get_status():
    # å›å‚³ç‹€æ…‹ä¹ŸåŒ…å«éŒ„å½±è³‡è¨Š
    return jsonify({
        "count": current_ball_count, 
        "tx": current_target_x, 
        "ty": current_target_y,
        "is_recording": is_recording
    })

@app.route('/video_feed')
def video_feed():
    def generate():
        while True:
            with lock:
                if output_frame is None: continue
                ret, b = cv2.imencode('.jpg', output_frame, [cv2.IMWRITE_JPEG_QUALITY, 50])
                f_bytes = b.tobytes()
            yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + f_bytes + b'\r\n')
            time.sleep(0.04)
    return Response(generate(), mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    # è‡ªå‹•åµæ¸¬ RoboRIO
    ROBORIO_IP = "10.60.83.2"
    print(f"æ­£åœ¨ Ping åµæ¸¬ RoboRIO ({ROBORIO_IP})...")
    response = os.system(f"ping -c 1 -W 1 {ROBORIO_IP} > /dev/null 2>&1")

    if response == 0:
        print("âœ… æˆåŠŸé€£ç·šåˆ° RoboRIOï¼è‡ªå‹•å•Ÿå‹• NetworkTables æ¨¡å¼ã€‚")
        ENABLE_NT = True
    else:
        print("âš ï¸ æ‰¾ä¸åˆ° RoboRIOã€‚è‡ªå‹•é€²å…¥ã€Œå–®æ©Ÿæ¸¬è©¦æ¨¡å¼ã€ã€‚")
        ENABLE_NT = False

    subprocess.run(["sudo", "fuser", "-k", "5000/tcp"], capture_output=True)
    threading.Thread(target=vision_worker, daemon=True).start()
    app.run(host='0.0.0.0', port=5000, threaded=True, debug=False, use_reloader=False)